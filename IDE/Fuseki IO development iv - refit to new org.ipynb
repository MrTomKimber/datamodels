{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from rdflib.plugins.stores import sparqlstore\n",
    "import rdflib\n",
    "from rdflib import URIRef, Literal, Graph, Dataset\n",
    "\n",
    "import serialization\n",
    "import discourse\n",
    "\n",
    "import html\n",
    "import loader\n",
    "import discourse\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "import io\n",
    "import pydotplus\n",
    "from IPython.display import display, Image\n",
    "from rdflib.tools.rdf2dot import rdf2dot\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import uuid\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def visualize(g):\n",
    "    stream = io.StringIO()\n",
    "    rdf2dot(g, stream, opts = {display})\n",
    "    dg = pydotplus.graph_from_dot_data(stream.getvalue())\n",
    "    png = dg.create_png()\n",
    "\n",
    "    display(Image(png))\n",
    "\n",
    "def t2rdflibg(triples): #triples to rdflib graph\n",
    "    g = Graph()\n",
    "    for t in triples:\n",
    "        g.add(t)\n",
    "    return g\n",
    "\n",
    "\n",
    "def nan2None(value):\n",
    "    if pd.isnull(value) :\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def get_data_rows(filename):\n",
    "    data_rows_df = pd.read_csv(filename)\n",
    "    data_rows=[]\n",
    "    for i,r in data_rows_df.iterrows():\n",
    "        r_d = {k:nan2None(v) for k,v in dict(r).items()}\n",
    "\n",
    "        data_rows.append(r_d)\n",
    "    del data_rows_df\n",
    "    return data_rows\n",
    "\n",
    "\n",
    "jena = sparqlstore.SPARQLUpdateStore(\"http://localhost:3030/modelg/query\",context_aware=True)\n",
    "jena.open((\"http://localhost:3030/modelg/query\", \"http://localhost:3030/modelg/update\"))\n",
    "#jena.open((\"http://localhost:3030/models/query\", \"http://localhost:3030/models/update\"))\n",
    "\n",
    "# Create a Dataset\n",
    "ds = Dataset(store=jena, default_union=True, default_graph_base=\"http://base.raw\")\n",
    "#ds = Dataset(store=jena, default_union=True)\n",
    "# Define a named graph within the dataset, this will contain all nodes contained within the graph referenced, or none if it doesn't exist yet.\n",
    "sg_uri = \"http://config\"\n",
    "masterg_uri = \"http://master\"\n",
    "discourseg_uri = \"http://discourse\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_data_package_template(field_d):\n",
    "    dc_terms_base = \"http://purl.org/dc/terms/\"\n",
    "    rdf_form = {}\n",
    "    for k,v in field_d.items():\n",
    "        rdf_form[URIRef(dc_terms_base + k)] = Literal(v)\n",
    "    return rdf_form\n",
    "\n",
    "\n",
    "def triples_to_quads(triples, graph=\"http://master\"):\n",
    "    for s,p,o, *_ in triples:\n",
    "        yield (s,p,o,URIRef(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to populate the config graph with some contents from an rdf file, if it's not already populated\n",
    "# This method is incredibly slow, but (should) only be necessary on the occasions where the database\n",
    "# is being populated from scratch. There are probably better ways to insert contents of a graph into the db\n",
    "# and this might be something to revisit later on. \n",
    "sg = ds.graph(URIRef(sg_uri))\n",
    "if len(sg)==0:\n",
    "    sg.parse(\"DMEAR_ser.rdf\")\n",
    "#S = serialization.Serialization(sg, \"EntityAttributeRecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = ds.graph(URIRef(masterg_uri))\n",
    "if len(mg)==0:\n",
    "    mg.parse(\"master_graph.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = ds.graph(URIRef(discourseg_uri))\n",
    "if len(dg)==0:\n",
    "    dg.parse(\"discourse_graph.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dtypes = {'ModelDomain': str,\n",
    " 'Model': str,\n",
    " 'ModelType': str,\n",
    " 'Class': str,\n",
    " 'ClassDescription': str,\n",
    " 'Attribute': str,\n",
    " 'AttributeDescription': str,\n",
    " 'DataType': str,\n",
    " 'Context': str,\n",
    " 'SubContext': str,\n",
    " 'Nulls': str,\n",
    " 'Is PK': str,\n",
    " 'Relationship': str,\n",
    " 'FromClass': str,\n",
    " 'FromAttribute': str,\n",
    " 'FromCardinality': str,\n",
    " 'ToClass': str,\n",
    " 'ToAttribute': str,\n",
    " 'ToCardinality': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(v):\n",
    "    if isinstance(v,str):\n",
    "        return html.escape(str(v))\n",
    "    elif isinstance(v,(int, float)):\n",
    "        if pd.isnull(v):\n",
    "            return None\n",
    "        else:\n",
    "            return v\n",
    "    elif v is None or isinstance(v,pd.Null):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Delete data hosted in master and discourse database graphs\n",
    "do=\"Yes\"\n",
    "do=\"No\"\n",
    "\n",
    "if do == \"Yes\":\n",
    "    try:\n",
    "        ds.update(\"\"\"CLEAR GRAPH <http://master>\"\"\")\n",
    "    except HTTPError:\n",
    "        pass\n",
    "    ds.update(\"\"\"CREATE GRAPH <http://master>\"\"\")\n",
    "    try:\n",
    "        ds.update(\"\"\"CLEAR GRAPH <http://discourse>\"\"\")\n",
    "    except HTTPError:\n",
    "        pass\n",
    "    ds.update(\"\"\"CREATE GRAPH <http://discourse>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ds = Dataset(store=jena, default_union=True, default_graph_base=\"http://base.raw\")\n",
    "#master_g = ds.graph(URIRef(\"http://master\"))\n",
    "#discourse_g = ds.graph(URIRef(\"http://discourse\"))\n",
    "rs = ds.query(\"\"\"select distinct ?g WHERE { GRAPH ?g { ?s ?p ?o .}}\"\"\")\n",
    "rg_set = set(pd.DataFrame(rs, columns=[\"graph\"])['graph'].apply(lambda x : x.n3()[1:-1]))\n",
    "required_graphs = [\"http://master\", \"http://discourse\"]\n",
    "for g in required_graphs:\n",
    "    if g not in rg_set:\n",
    "        print(g)\n",
    "#        tg = ds.graph(URIRef(g))\n",
    "        create_graph_sparql = \"\"\"CREATE GRAPH {gn}\"\"\".format(gn=URIRef(g).n3())\n",
    "        print(create_graph_sparql)\n",
    "        ds.update(create_graph_sparql)\n",
    "        \n",
    "rs = ds.query(\"\"\"select distinct ?g WHERE { GRAPH ?g { ?s ?p ?o .}}\"\"\")\n",
    "rg_set = set(pd.DataFrame(rs, columns=[\"graph\"])['graph'].apply(lambda x : x.n3()[1:-1]))\n",
    "rg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 28\u001b[0m\n\u001b[1;32m      1\u001b[0m discourse_details_sparql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mPREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124mGROUP BY ?g ?discourse ?name ?title ?description ?created ?hash\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m qr \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mquery(discourse_details_sparql)\n\u001b[1;32m     29\u001b[0m discourse_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(qr, columns\u001b[38;5;241m=\u001b[39m[v\u001b[38;5;241m.\u001b[39mn3()[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m qr\u001b[38;5;241m.\u001b[39mvars])\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m discourse_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhash_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mdiscourse_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39mn3()[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "discourse_details_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \n",
    "PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "select ?g ?discourse ?name ?title ?description ?created ?hash (COUNT(?declaration) as ?declarations) (COUNT(distinct ?psubject) as ?entities)\n",
    "\n",
    "WHERE {\n",
    "  GRAPH ?g\n",
    "  {\n",
    "      ?discourse a disco:Discourse.\n",
    "      ?discourse dcterms:title ?title.\n",
    "      ?discourse rdfs:label ?name.\n",
    "      ?discourse dcterms:description ?description.\n",
    "      ?discourse dcterms:created ?created .\n",
    "      ?discourse disco:DiscourseHash ?hash .\n",
    "      ?discourse disco:DiscourseContains+ ?declaration .\n",
    "      ?declaration a disco:Declaration .\n",
    "      ?posit_type rdfs:subPropertyOf* disco:Posits .\n",
    "      ?declaration disco:Asserts ?assertion.\n",
    "      ?assertion disco:Subject ?psubject.\n",
    "  }\n",
    "}\n",
    "GROUP BY ?g ?discourse ?name ?title ?description ?created ?hash\n",
    "\"\"\"\n",
    "\n",
    "qr = ds.query(discourse_details_sparql)\n",
    "discourse_df = pd.DataFrame(qr, columns=[v.n3()[1:] for v in qr.vars]).sort_values(by=\"created\")\n",
    "discourse_df[\"hash_vals\"]=discourse_df['hash'].apply(lambda x : x.n3()[1:-1])\n",
    "discourse_df.set_index(\"discourse\", inplace=True)\n",
    "discourse_df\n",
    "hash_discourse_mapping = {v:k for k,v in dict(discourse_df['hash'].apply(lambda x : x.n3()[1:-1])).items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_discourse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmg\u001b[49m\u001b[38;5;241m.\u001b[39m_Graph__identifier\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mg' is not defined"
     ]
    }
   ],
   "source": [
    "mg._Graph__identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Inventory ERD v1.0\"\n",
    "model_data = pd.read_csv(r\"../sample/inventory_v1.csv\", index_col=\"Sequence\", dtype=file_dtypes)\n",
    "rows = [dict({rk:get_field(rv) for rk, rv in r.items()}) for i,r in model_data.iterrows()]\n",
    "md_p = meta_data_package_template( {\"created\" : \"2023-04-10\", \n",
    "                                   \"creator\" : \"tomk\", \n",
    "                                   \"description\" : \"Sample ERD model version 1\", \n",
    "                                   \"title\" : \"inventory ERD\", \n",
    "                                   \"modified\" : \"2023-04-10\"})\n",
    "\n",
    "loader.load_to_graph(ds, sg_uri, \"EntityAttributeRecord\", rows, masterg_uri, discourseg_uri, title, md_p, hash_discourse_mapping, override_duplicate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Inventory ERD v2.0\"\n",
    "model_data = pd.read_csv(r\"../sample/inventory_v2.csv\", index_col=\"Sequence\", dtype=file_dtypes)\n",
    "rows = [dict({rk:get_field(rv) for rk, rv in r.items()}) for i,r in model_data.iterrows()]\n",
    "md_p = meta_data_package_template( {\"created\" : \"2023-04-11\", \n",
    "                                   \"creator\" : \"tomk\", \n",
    "                                   \"description\" : \"Sample ERD model version 2\", \n",
    "                                   \"title\" : \"inventory ERD\", \n",
    "                                   \"modified\" : \"2023-04-11\"})\n",
    "\n",
    "loader.load_to_graph(ds, sg_uri, \"EntityAttributeRecord\", rows, masterg_uri, discourseg_uri, title, md_p, hash_discourse_mapping, override_duplicate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Inventory ERD v3.0\"\n",
    "model_data = pd.read_csv(r\"../sample/inventory_v3.csv\", index_col=\"Sequence\", dtype=file_dtypes)\n",
    "rows = [dict({rk:get_field(rv) for rk, rv in r.items()}) for i,r in model_data.iterrows()]\n",
    "md_p = meta_data_package_template( {\"created\" : \"2023-04-14\", \n",
    "                                   \"creator\" : \"tomk\", \n",
    "                                   \"description\" : \"Sample ERD model version 3\", \n",
    "                                   \"title\" : \"inventory ERD\", \n",
    "                                   \"modified\" : \"2023-04-14\"})\n",
    "\n",
    "loader.load_to_graph(ds, sg_uri, \"EntityAttributeRecord\", rows, masterg_uri, discourseg_uri, title, md_p, hash_discourse_mapping, override_duplicate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Tell me what discourses are available in the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_details_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \n",
    "PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "select ?g ?discourse ?name ?title ?description ?created ?hash (COUNT(?declaration) as ?declarations) (COUNT(distinct ?psubject) as ?entities)\n",
    "\n",
    "WHERE {\n",
    "  GRAPH ?g\n",
    "  {\n",
    "      ?discourse a disco:Discourse.\n",
    "      ?discourse dcterms:title ?title.\n",
    "      ?discourse rdfs:label ?name.\n",
    "      ?discourse dcterms:description ?description.\n",
    "      ?discourse dcterms:created ?created .\n",
    "      ?discourse disco:DiscourseHash ?hash .\n",
    "      ?discourse disco:DiscourseContains+ ?declaration .\n",
    "      ?declaration a disco:Declaration .\n",
    "      ?posit_type rdfs:subPropertyOf* disco:Posits .\n",
    "      ?declaration disco:Asserts ?assertion.\n",
    "      ?assertion disco:Subject ?psubject.\n",
    "  }\n",
    "}\n",
    "GROUP BY ?g ?discourse ?name ?title ?description ?created ?hash\n",
    "\"\"\"\n",
    "\n",
    "qr = ds.query(discourse_details_sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df = pd.DataFrame(qr, columns=[v.n3()[1:] for v in qr.vars]).sort_values(by=\"created\")\n",
    "discourse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_details_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \n",
    "PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "select ?g ?discourse ?name ?title ?description ?created ?hash (COUNT(?declaration) as ?declarations) (COUNT(distinct ?psubject) as ?entities)\n",
    "\n",
    "WHERE {\n",
    "  GRAPH ?g\n",
    "  {\n",
    "      ?discourse a disco:Discourse.\n",
    "      ?discourse dcterms:title ?title.\n",
    "      ?discourse rdfs:label ?name.\n",
    "      ?discourse dcterms:description ?description.\n",
    "      ?discourse dcterms:created ?created .\n",
    "      ?discourse disco:DiscourseHash ?hash .\n",
    "      ?discourse disco:DiscourseContains+ ?declaration .\n",
    "      ?declaration a disco:Declaration .\n",
    "      ?posit_type rdfs:subPropertyOf* disco:Posits .\n",
    "      ?declaration disco:Asserts ?assertion.\n",
    "      ?assertion disco:Subject ?psubject.\n",
    "  }\n",
    "}\n",
    "GROUP BY ?g ?discourse ?name ?title ?description ?created ?hash\n",
    "\"\"\"\n",
    "\n",
    "qr = ds.query(discourse_details_sparql)\n",
    "discourse_df = pd.DataFrame(qr, columns=[v.n3()[1:] for v in qr.vars]).sort_values(by=\"created\")\n",
    "discourse_df[\"hash_vals\"]=discourse_df['hash'].apply(lambda x : x.n3()[1:-1])\n",
    "discourse_df.set_index(\"discourse\", inplace=True)\n",
    "discourse_df\n",
    "hash_discourse_mapping = {v:k for k,v in dict(discourse_df['hash'].apply(lambda x : x.n3()[1:-1])).items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Inventory ERD v1.0\"\n",
    "model_data = pd.read_csv(r\"../sample/inventory_v1.csv\", index_col=\"Sequence\", dtype=file_dtypes)\n",
    "rows = [dict({rk:get_field(rv) for rk, rv in r.items()}) for i,r in model_data.iterrows()]\n",
    "md_p = meta_data_package_template( {\"created\" : \"2023-04-10\", \n",
    "                                   \"creator\" : \"tomk\", \n",
    "                                   \"description\" : \"Sample ERD model version 1\", \n",
    "                                   \"title\" : \"inventory ERD\", \n",
    "                                   \"modified\" : \"2023-04-10\"})\n",
    "\n",
    "loader.load_to_graph(ds, sg_uri, \"EntityAttributeRecord\", rows, masterg_uri, discourseg_uri, title, md_p, hash_discourse_mapping, override_duplicate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.data.world/tutorials/sparql/list-of-sparql-filter-functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_details_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \n",
    "PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "select ?g ?discourse ?name ?title ?description ?created ?hash (COUNT(?declaration) as ?declarations) (COUNT(distinct ?psubject) as ?entities)\n",
    "\n",
    "WHERE {\n",
    "  GRAPH ?g\n",
    "  {\n",
    "      ?discourse a disco:Discourse.\n",
    "      ?discourse dcterms:title ?title.\n",
    "      ?discourse rdfs:label ?name.\n",
    "      ?discourse dcterms:description ?description.\n",
    "      ?discourse dcterms:created ?created .\n",
    "      ?discourse disco:DiscourseHash ?hash .\n",
    "      ?discourse disco:DiscourseContains+ ?declaration .\n",
    "      ?declaration a disco:Declaration .\n",
    "      ?posit_type rdfs:subPropertyOf* disco:Posits .\n",
    "      ?declaration disco:Asserts ?assertion.\n",
    "      ?assertion disco:Subject ?psubject.\n",
    "  }\n",
    "}\n",
    "GROUP BY ?g ?discourse ?name ?title ?description ?created ?hash\n",
    "\"\"\"\n",
    "\n",
    "qr = ds.query(discourse_details_sparql)\n",
    "discourse_df = pd.DataFrame(qr, columns=[v.n3()[1:] for v in qr.vars]).sort_values(by=\"created\")\n",
    "discourse_df[\"hash_vals\"]=discourse_df['hash'].apply(lambda x : x.n3()[1:-1])\n",
    "discourse_df.set_index(\"discourse\", inplace=True)\n",
    "discourse_df\n",
    "#hash_discourse_mapping = {v:k for k,v in dict(discourse_df['hash'].apply(lambda x : x.n3()[1:-1])).items()}\n",
    "discourse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourses = list(discourse_df.index)\n",
    "discourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourses[0].n3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_discourse_posits_sparql = \"\"\"\n",
    "\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \n",
    "PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "\n",
    "select ?g ?discourse ?a ?r ?p\n",
    "WHERE {\n",
    "  GRAPH ?g\n",
    "  {\n",
    "      ?discourse a disco:Discourse.\n",
    "      ?discourse disco:DiscourseContains+ ?declaration .\n",
    "      ?declaration a disco:Declaration .\n",
    "        OPTIONAL { ?declaration disco:Asserts ?a. \n",
    "                   }\n",
    "        OPTIONAL { ?declaration disco:Refutes ?r. \n",
    "                   }\n",
    "        OPTIONAL { ?declaration disco:Posits ?p. \n",
    "        }\n",
    "      \n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qr = ds.query(get_discourse_posits_sparql)\n",
    "\n",
    "pd.DataFrame(qr, columns=[\"g\",\"d\",\"a\",\"r\",\"p\"]).groupby([\"g\",\"d\"]).agg(set)#.iloc[2]['a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = pd.DataFrame(qr, columns=[\"g\",\"d\",\"a\",\"r\",\"p\"]).groupby([\"g\",\"d\"]).agg(set)[['a']].values\n",
    "for i,x in enumerate(av):\n",
    "    for j,y in enumerate(av):\n",
    "        if i!=j:\n",
    "            print((i,j),len(set(x[0]).difference(set(y[0]))), len(set(x[0]).intersection(set(y[0]))), len(set(y[0]).difference(set(x[0]))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given two discourse urls, d1, d2, pull all the discourse-data associated \n",
    "# - including the reified triples they reference\n",
    "\n",
    "\n",
    "get_posits_by_discourse_sparql = \"\"\"\n",
    "\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX disco: <http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#> \n",
    "PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "select ?g ?discourse ?assertion ?refutation ?posit ?s ?p ?o\n",
    "WHERE {\n",
    "  GRAPH ?g\n",
    "  {\n",
    "      ?discourse a disco:Discourse.\n",
    "      ?discourse disco:DiscourseContains+ ?declaration .\n",
    "      ?declaration a disco:Declaration .\n",
    "        OPTIONAL { ?declaration disco:Asserts ?assertion. \n",
    "                   ?assertion disco:Subject ?s.\n",
    "                   ?assertion disco:Predicate ?p.\n",
    "                   ?assertion disco:Object ?o.\n",
    "                   }\n",
    "        OPTIONAL { ?declaration disco:Refutes ?refutation. \n",
    "                   ?refutation disco:Subject ?s.\n",
    "                   ?refutation disco:Predicate ?p.\n",
    "                   ?refutation disco:Object ?o.\n",
    "                   }\n",
    "        OPTIONAL { ?declaration disco:Posits ?posit. \n",
    "                   ?posit disco:Subject ?s.\n",
    "                   ?posit disco:Predicate ?p.\n",
    "                   ?posit disco:Object ?o.\n",
    "        }\n",
    "      FILTER (?discourse IN ( %%d1%%, %%d2%% )) .\n",
    "      \n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\".replace(\"%%d1%%\",discourses[2].n3()).replace(\"%%d2%%\", discourses[3].n3())\n",
    "\n",
    "qr = ds.query(get_posits_by_discourse_sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_contents = pd.DataFrame(qr, columns=[v.n3()[1:] for v in qr.vars]).sort_values(by=\"discourse\")\n",
    "discourse_contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_contents['triple'] = discourse_contents.apply(lambda x : tuple([x['s'], x['p'], x['o']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_set_d = discourse_contents.groupby(['discourse'])['triple'].agg(set).to_dict()\n",
    "\n",
    "\n",
    "#d_set_d = discourse_contents.groupby(['discourse']).agg(set).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_l = list(d_set_d.keys())\n",
    "key_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffset(S1, S2):\n",
    "    # Given two input sets, s1 and s2, return the Left difference, Intersection and Right difference between them\n",
    "    L = S1.difference(S2)\n",
    "    I = S1.intersection(S2)\n",
    "    R = S2.difference(S1)\n",
    "    return L,I,R\n",
    "\n",
    "def LIR_to_lookup(L,I,R):\n",
    "    # Given three input sets of triples, recombine them into a single\n",
    "    # dictionary, where each triple acts as a key, referencing a string\n",
    "    # value in the set {\"L\", \"I\", \"R\"} to return the source of the triple\n",
    "    # The same effect could be performed by running a series of 'in' tests\n",
    "    # to see which set a given triple resides, but here a dictionary is \n",
    "    # provided to support this operation.\n",
    "    lir_dict = {}\n",
    "    lir_labels = [\"L\",\"I\",\"R\"]\n",
    "    for e,d in enumerate([L,I,R]):\n",
    "        for t in d:\n",
    "            lir_dict[t]=lir_labels[e]\n",
    "    return lir_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(left_diff, intersection, right_diff)\")\n",
    "s1,s2 = d_set_d[key_l[0]], d_set_d[key_l[1]]\n",
    "diffs = diffset(s1,s2)\n",
    "[len(d) for d in diffs], len(s1), len(s2)\n",
    "LIR_to_lookup(*diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_set(triple_set, indx):\n",
    "    subjects=set()\n",
    "    for t in triple_set:\n",
    "        subjects.add(t[indx])\n",
    "    return subjects\n",
    "\n",
    "def get_subjects(triple_set):\n",
    "    return get_atom_set(triple_set, 0)\n",
    "\n",
    "def get_predicates(triple_set):\n",
    "    return get_atom_set(triple_set, 1)\n",
    "\n",
    "def get_objects(triple_set):\n",
    "    return get_atom_set(triple_set, 2)\n",
    "\n",
    "def get_type_atoms(triple_set, indx):\n",
    "    typed=set()\n",
    "    for t in triple_set:\n",
    "        if t[1]==URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"):\n",
    "            typed.add(t[indx])\n",
    "    return typed\n",
    "\n",
    "def filter_type_triples(triple_set):\n",
    "    typed=set()\n",
    "    for t in triple_set:\n",
    "        if t[1]==URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"):\n",
    "            typed.add(t)\n",
    "    return typed\n",
    "    \n",
    "\n",
    "def get_types(triple_set):\n",
    "    return get_type_atoms(triple_set, 2)\n",
    "\n",
    "def get_typed_objects(triple_set):\n",
    "    return get_type_atoms(triple_set, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _addN(graph, triples):\n",
    "    for t in triples:\n",
    "        graph.add(t)\n",
    "    return graph\n",
    "\n",
    "# Feed diffset split sets of SPO triples\n",
    "def visualise_ERD_diffset(L, I, R):\n",
    "#    L = original only\n",
    "#    I = both\n",
    "#    R = new only\n",
    "    lir_graphs = _addN(Graph(), L), _addN(Graph(), I), _addN(Graph(), R)\n",
    "    # Extract identifiers for all main model components\n",
    "    lir_entities = [[s for s,p,o in gg.triples((None, URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), URIRef('http://www.semanticweb.org/tomk/ontologies/2022/9/datamodel#Class')))] for gg in lir_graphs]\n",
    "    lir_attributes = [[s for s,p,o in gg.triples((None, URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), URIRef('http://www.semanticweb.org/tomk/ontologies/2022/9/datamodel#Attribute')))] for gg in lir_graphs]\n",
    "    \n",
    "    print(lir_entities, \"\\n\\n\", lir_models)\n",
    "    return l_graph\n",
    "    \n",
    "\n",
    "\n",
    "def process_diffs(S1, S2):\n",
    "    # Accepting two sets of triples as input, \n",
    "    # Decompose into a dictionary keyed on rdf:type whose values \n",
    "    # are the subjects of those types, segmented into L,I,R \n",
    "    # { rdf:type : ( subject, {L,I,R}label)}\n",
    "    # From there, the user can cycle over entities of interest\n",
    "    \n",
    "    rdftype_uri = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')\n",
    "    U = S1.union(S2)\n",
    "    class_d = LIR_to_lookup(*diffset(S1, S2))\n",
    "    U_g = _addN(Graph(),U)\n",
    "    type_s = get_types(U)\n",
    "    t_subjs={}\n",
    "    for t in type_s: # Create a dictionary, whose keys are type, and whose values are the subjects of those types.\n",
    "        t_subjs[t]=[(s,class_d[(s,p,o)]) for s,p,o in U_g.triples((None, rdftype_uri, t))]\n",
    "        \n",
    "\n",
    "    mdk = rdflib.term.URIRef('http://www.semanticweb.org/tomk/ontologies/2022/9/datamodel#Class')\n",
    "    for v in t_subjs[mdk]: \n",
    "        t_list = list(U_g.triples((v[0], None, None)))\n",
    "        #print(t_list)\n",
    "    \n",
    "    \n",
    "    return t_subjs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_subjs = process_diffs(s1, s2)\n",
    "#t_subjs[rdflib.term.URIRef('http://www.semanticweb.org/tomk/ontologies/2022/9/datamodel#ModelDomain')]\n",
    "t_subjs[rdflib.term.URIRef('http://www.semanticweb.org/tomk/ontologies/2022/9/datamodel#Model')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L,I,R = diffset(s1, s2)\n",
    "subset = get_subjects(I)\n",
    "predset = get_predicates(I) \n",
    "obset = get_objects(I)\n",
    "typeset = get_typed_objects(I)\n",
    "types = get_types(I)\n",
    "\n",
    "typeset.symmetric_difference(obset).symmetric_difference(types)\n",
    "#list(ds.triples((URIRef('http://www.semanticweb.org/tomk/ontologies/2022/11/b3b0fd89605e4d04a3f698d974d3579f'), None, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(t2rdflibg(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(q) for q in [L,I,R]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discourse_contents[discourse_contents['p']==][['s','p','o']]\n",
    "discourse_contents[['s','p','o']].groupby(\"p\").agg(set).loc[URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')]['o']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(t2rdflibg( discourse_contents[discourse_contents['discourse']==discourses[1]][['s','p','o']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET.register_namespace('rdf',\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_map = [('rdf',\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"),\n",
    "          ('dc',\"http://purl.org/dc/elements/1.1/\"),\n",
    "          ('rdfs',\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "         ]\n",
    "name = \"http://master\"\n",
    "g_context = { \"dc:created\" : datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "              \"dc:description\":\"\"\"The master graph is used to store all mastered triples. It acts as a \"soup\" of expressable content, primarily for entities to be identified by their properties for the purposes of identifying unique individuals. \"\"\"}\n",
    "\n",
    "g_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_named_graph_manifest_rdf_xml(graph_uri, namespaces, properties):\n",
    "    X = ET.Element('rdf:RDF')\n",
    "    for prefix, uri  in namespaces:\n",
    "        X.set(\"xmlns:\" + prefix, uri)\n",
    "    q = ET.SubElement(X, \"rdf:Description\")\n",
    "    q.set(\"rdf:about\", graph_uri)\n",
    "    for t,v in g_context.items():\n",
    "        a = ET.SubElement(q, t)\n",
    "        a.text = v\n",
    "    ET.indent(X, space=\"\\t\", level=0)\n",
    "    return ET.tostring(X).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_text = create_graph_manifest_rdf_xml(\"http://master\", ns_map, g_context)\n",
    "print(xml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
