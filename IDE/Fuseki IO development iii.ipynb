{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "* Owlready2 * WARNING: ObjectProperty http://www.semanticweb.org/tomk/ontologies/2022/11/serialization#MappingMetaTarget belongs to more than one entity types: [owl.AnnotationProperty, owl.ObjectProperty, owl.topObjectProperty]; I'm trying to fix it...\n",
      "* Owlready2 * Running HermiT...\n",
      "    java -Xmx2000M -cp /usr/local/python/py36/lib/python3.6/site-packages/owlready2/hermit:/usr/local/python/py36/lib/python3.6/site-packages/owlready2/hermit/HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:////var/folders/rd/q3bhk6_n56x75m05pp2sq7dr0000gn/T/tmpj9x_2vs5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialization.Meta [Serialization.SerializationMetaData]\n",
      "Serialization.Mapping [Serialization.SerializationSpecs]\n",
      "Serialization.BatchDefinition [Serialization.SerializationSpecs]\n",
      "Serialization.SerializationSpecs [Serialization.SerializationMetaData]\n",
      "Serialization.BatchNode [Serialization.DataLoad]\n",
      "Serialization.DataLoad [Serialization.SerializationMetaData]\n",
      "Serialization.SerializationMetaData [owl.Thing]\n",
      "Serialization.DataPropertyMapping [Serialization.Mapping]\n",
      "Serialization.MetaDataProperty [Serialization.Meta]\n",
      "Serialization.EntityMapping [Serialization.Mapping]\n",
      "Serialization.MetaClass [Serialization.Meta]\n",
      "Serialization.JobNode [Serialization.DataLoad]\n",
      "Serialization.MetaProperty [Serialization.Meta]\n",
      "Serialization.PropertyMapping [Serialization.Mapping]\n",
      "Serialization.RowNode [Serialization.DataLoad]\n",
      "Serialization.Serialization [Serialization.SerializationSpecs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * HermiT took 0.7655632495880127 seconds\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "from rdflib.plugins.stores import sparqlstore\n",
    "import rdflib\n",
    "from rdflib import URIRef, Literal, Graph, Dataset\n",
    "\n",
    "import serialization\n",
    "import discourse\n",
    "\n",
    "import html\n",
    "import loader\n",
    "import discourse\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "import io\n",
    "import pydotplus\n",
    "from IPython.display import display, Image\n",
    "from rdflib.tools.rdf2dot import rdf2dot\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import uuid\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "def visualize(g):\n",
    "    stream = io.StringIO()\n",
    "    rdf2dot(g, stream, opts = {display})\n",
    "    dg = pydotplus.graph_from_dot_data(stream.getvalue())\n",
    "    png = dg.create_png()\n",
    "\n",
    "    display(Image(png))\n",
    "\n",
    "def t2rdflibg(triples): #triples to rdflib graph\n",
    "    g = Graph()\n",
    "    for t in triples:\n",
    "        g.add(t)\n",
    "    return g\n",
    "\n",
    "\n",
    "def nan2None(value):\n",
    "    if pd.isnull(value) :\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def get_data_rows(filename):\n",
    "    data_rows_df = pd.read_csv(filename)\n",
    "    data_rows=[]\n",
    "    for i,r in data_rows_df.iterrows():\n",
    "        r_d = {k:nan2None(v) for k,v in dict(r).items()}\n",
    "\n",
    "        data_rows.append(r_d)\n",
    "    del data_rows_df\n",
    "    return data_rows\n",
    "\n",
    "serial_key = { \"Business Domain\" : \"ModelDomain\", \n",
    "               \"Model\" : \"Model\", \n",
    "               \"ModelType\" : \"ModelType\", \n",
    "               \"Entity\" : \"Class\", \n",
    "               \"Attribute\" : \"Attribute\", \n",
    "               \"DataType\" : \"DataType\", \n",
    "               \"Context\" : \"Context\", \n",
    "               \"SubContext\" : \"SubContext\", \n",
    "               \"Relationship\" : \"Relationship\", \n",
    "               \"Entity From\" : \"FromClass\",\n",
    "               \"Attribute From\" : \"FromAttribute\", \n",
    "               \"Cardinality From\" : \"FromCardinality\",\n",
    "               \"Entity To\" : \"ToClass\",\n",
    "               \"Attribute To\" : \"ToAttribute\",\n",
    "               \"Cardinality To\" : \"ToCardinality\"\n",
    "}\n",
    "\n",
    "jena = sparqlstore.SPARQLUpdateStore(\"http://localhost:3030/modelg/query\",context_aware=True)\n",
    "#jena.open((\"http://localhost:3030/modelg/query\", \"http://localhost:3030/modelg/update\"))\n",
    "jena.open((\"http://localhost:3030/models/query\", \"http://localhost:3030/models/update\"))\n",
    "\n",
    "# Create a Dataset\n",
    "ds = Dataset(store=jena, default_union=True, default_graph_base=\"http://base.raw\")\n",
    "#ds = Dataset(store=jena, default_union=True)\n",
    "# Define a named graph within the dataset, this will contain all nodes contained within the graph referenced, or none if it doesn't exist yet.\n",
    "sg = ds.graph(URIRef(\"http://config\"))\n",
    "sg = Graph()\n",
    "master_g = ds.graph(URIRef(\"http://master\"))\n",
    "discourse_g = ds.graph(URIRef(\"http://discourse\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv(r\"mdm_v11_3_pdm_additional.csv\").fillna(\"\")\n",
    "model_data.columns=['Sequence', 'ModelDomain', 'Model', 'ModelType', 'Class',\n",
    "       'ClassDescription', 'Attribute', 'AttributeDescription', 'DataType',\n",
    "       'Context', 'SubContext', 'Nulls', 'Is PK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_filter(keys,xlist=None):\n",
    "    s_keys = sorted(keys)\n",
    "    if xlist is not None:\n",
    "        if not tuple([k for k in s_keys if k not in xlist]) == tuple():\n",
    "            s_keys = tuple([k for k in s_keys if k not in xlist])\n",
    "        else:\n",
    "            s_keys = tuple(s_keys)\n",
    "\n",
    "    else:\n",
    "        s_keys = tuple([k for k in s_keys])\n",
    "    return s_keys\n",
    "\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "fkf = partial(key_filter, xlist=[\"LANG_TP_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('BKTHASH', 'RECNO', 'SRCRECNO'), 1),\n",
       " (('CMPSEQNO', 'RECNO'), 1),\n",
       " (('SRCID', 'SRCRECNO'), 1),\n",
       " (('CITY_NAME',\n",
       "   'GIVEN_NAME_ONE',\n",
       "   'LAST_NAME',\n",
       "   'P_CITY_NAME',\n",
       "   'P_GIVEN_NAME_ONE',\n",
       "   'P_LAST_NAME'),\n",
       "  1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_keys = dict(model_data[model_data['Is PK']==\"Yes\"].groupby(\"Class\")['Attribute'].agg(fkf))\n",
    "[(k,v) for k,v in Counter(raw_keys.values()).items() if len(k)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('LOCATION_GROUP_ID',), 3), (('PAYMENT_SOURCE_ID',), 4), (('CONT_ID',), 6), (('PRODUCT_ID',), 5), (('HOLDING_ID',), 3), (('PPREF_ID',), 3), (('SUSPECT_ID',), 2)]\n"
     ]
    }
   ],
   "source": [
    "# Contents here block the inversion of the table/pk mapping dict\n",
    "print([(k,v) for k,v in Counter(raw_keys.values()).items() if v>1])\n",
    "# FOR IBM products, sharing the same PK implies parent/sub-class relationships (though there's)\n",
    "# no systematic method for determining which one is the parent.\n",
    "sorted([(k,v) for k,v in raw_keys.items() if v in [k for k,v in Counter(raw_keys.values()).items() if v>1]], key=lambda x : x[1])\n",
    "manual_key_masters = { ('CONT_ID',) : 'CONTACT', \n",
    "                       ('HOLDING_ID',): 'HOLDING', \n",
    "                      ('LOCATION_GROUP_ID',) : 'LOCATIONGROUP', \n",
    "                      ('PAYMENT_SOURCE_ID', ): 'PAYMENTSOURCE',\n",
    "                      ('PPREF_ID',) : 'PRIVPREF',\n",
    "                      ('PRODUCT_ID',) : 'PRODUCT', \n",
    "                      ('SUSPECT_ID',) : 'SUSPECT' , \n",
    "                      ('LANG_TP_CD', ) : 'CDLANGTP'\n",
    "                     }\n",
    "\n",
    "key_map = {**{v:k for k,v in raw_keys.items()}, **manual_key_masters}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_link(row):\n",
    "    attribute=row['Attribute']\n",
    "    table = row['Class']\n",
    "    t_att = tuple([attribute])\n",
    "    t_val = key_map.get(t_att)\n",
    "    relationship = str(table) + \" --> \" + str(t_val)\n",
    "    if t_val is not None and t_val != table:\n",
    "        return pd.Series((relationship, table, attribute, t_val, t_att[0]))\n",
    "    else:\n",
    "        return pd.Series((None, None, None, None, None))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend model_data to include extracted relationship information\n",
    "model_data[['Relationship','FromClass','FromAttribute','ToClass','ToAttribute']] = model_data.apply(att_link, axis=1)\n",
    "#model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_data_package_template(field_d):\n",
    "    dc_terms_base = \"http://purl.org/dc/terms/\"\n",
    "    rdf_form = {}\n",
    "    for k,v in field_d.items():\n",
    "        rdf_form[URIRef(dc_terms_base + k)] = Literal(v)\n",
    "    return rdf_form\n",
    "\n",
    "\n",
    "\n",
    "d_p = meta_data_package_template( {\"created\" : \"2023-04-01\", \n",
    "                                   \"creator\" : \"tomk\", \n",
    "                                   \"description\" : \"test data package\", \n",
    "                                   \"title\" : \"some title\", \n",
    "                                   \"modified\" : \"2023-04-05\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [dict({rk:html.escape(str(rv)) for rk, rv in r.items()}) for i,r in model_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{rdflib.term.URIRef('http://purl.org/dc/terms/created'): rdflib.term.Literal('2023-04-01'),\n",
       " rdflib.term.URIRef('http://purl.org/dc/terms/creator'): rdflib.term.Literal('tomk'),\n",
       " rdflib.term.URIRef('http://purl.org/dc/terms/description'): rdflib.term.Literal('test data package'),\n",
       " rdflib.term.URIRef('http://purl.org/dc/terms/title'): rdflib.term.Literal('some title'),\n",
       " rdflib.term.URIRef('http://purl.org/dc/terms/modified'): rdflib.term.Literal('2023-04-05')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sg)==0:\n",
    "    sg.parse(\"DMEAR_ser.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sg.triples((None, None, None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = serialization.Serialization(sg, \"EntityAttributeRecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09.475771 for 1944\n"
     ]
    }
   ],
   "source": [
    "# Here master_g is a master graph sourced from Fuseki\n",
    "mq,me_m = loader.get_triples(sg, \"EntityAttributeRecord\", rows, master_g, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,de,di = loader.generate_discourse(\"test_123\", mq, d_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triples_to_quads(triples, graph=\"http://master\"):\n",
    "    for s,p,o, *_ in triples:\n",
    "        yield (s,p,o,URIRef(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_gen = triples_to_quads(mq, \"http://master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_quads = list(q_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13775, 96425, 55100, 13783)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mq), len(p), len(de), len(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds.addN(triples_to_quads(mq, URIRef(\"http://master\")))\n",
    "ds.addN(triples_to_quads(p, URIRef(\"http://discourse\")))\n",
    "ds.addN(triples_to_quads(de, URIRef(\"http://discourse\")))\n",
    "ds.addN(triples_to_quads(di, URIRef(\"http://discourse\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addN(triples_to_quads( [(URIRef('http://www.semanticweb.org/tomk/ontologies/2022/11/236472ed5205428f91f080ac2962229b'), \n",
    "  URIRef('http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#DiscourseContains'),\n",
    "  URIRef(\"disco_test\")),\n",
    "  (URIRef(\"disco_test\"),\n",
    "  URIRef('http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#DiscourseContains'),\n",
    "   URIRef(\"disco_test_thing\")),\n",
    " (URIRef(\"disco_test_thing\"),URIRef(\"rdf:type\"),URIRef(\"itchyness\"), \n",
    " )\n",
    "], URIRef(\"http://discourse\") ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "qr = discourse_g.query(\"\"\"select ?s ?p ?o {\n",
    "\n",
    " ?s ?p ?o. \n",
    " VALUES ?p {rdf:type}\n",
    "\n",
    "}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owlr\n",
    "disco = owlr.get_ontology(\"discourse.owl\").load()\n",
    "disco_ns = Namespace(disco.base_iri)\n",
    "discourse_g.bind('disco', disco_ns, override=True, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qr = discourse_g.query(\"\"\"select ?s ?p ?o {\n",
    "\n",
    " ?discourse rdf:type disco:Discourse. \n",
    " ?s ?p ?o.\n",
    " FILTER ( ?p = disco:DiscourseContains)\n",
    "\n",
    "}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qr = discourse_g.query(\"\"\"select ?discourse ?o ?t {\n",
    "\n",
    " ?discourse rdf:type disco:Discourse. \n",
    " ?discourse disco:DiscourseContains+ ?o .\n",
    " ?o rdf:type ?t.\n",
    "\n",
    "}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_last_values(v):\n",
    "    if isinstance(v, rdflib.URIRef):\n",
    "        return v.n3().split(\"/\")[-1][:-1]\n",
    "    else:\n",
    "        return type(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e006e98e3b6430a8b5b260426266922</td>\n",
       "      <td>48deac3462e74284b9cfcac12050aa0c</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e006e98e3b6430a8b5b260426266922</td>\n",
       "      <td>5c49be2c796a459f8f7e3999c6b7b30e</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e006e98e3b6430a8b5b260426266922</td>\n",
       "      <td>c31ab1a04c464304aadf5a373076a653</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e006e98e3b6430a8b5b260426266922</td>\n",
       "      <td>1536d26b1b7e42f7a5bc04484bdc2397</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e006e98e3b6430a8b5b260426266922</td>\n",
       "      <td>62f51c24b3e4455fa36aa7466e884608</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68870</th>\n",
       "      <td>236472ed5205428f91f080ac2962229b</td>\n",
       "      <td>5fd8a3d606ed40ba864c479a6bdf80f0</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68871</th>\n",
       "      <td>236472ed5205428f91f080ac2962229b</td>\n",
       "      <td>ca156c132a72490597e96a962e7ce7b4</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68872</th>\n",
       "      <td>236472ed5205428f91f080ac2962229b</td>\n",
       "      <td>fbf542e01e49423485ee6ed332170084</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68873</th>\n",
       "      <td>236472ed5205428f91f080ac2962229b</td>\n",
       "      <td>39579724cb2d447a8be28db79bca42e0</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68874</th>\n",
       "      <td>236472ed5205428f91f080ac2962229b</td>\n",
       "      <td>122710774f3e49279c225a1f521eb17b</td>\n",
       "      <td>discourse#Declaration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68875 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0                                 1  \\\n",
       "0      5e006e98e3b6430a8b5b260426266922  48deac3462e74284b9cfcac12050aa0c   \n",
       "1      5e006e98e3b6430a8b5b260426266922  5c49be2c796a459f8f7e3999c6b7b30e   \n",
       "2      5e006e98e3b6430a8b5b260426266922  c31ab1a04c464304aadf5a373076a653   \n",
       "3      5e006e98e3b6430a8b5b260426266922  1536d26b1b7e42f7a5bc04484bdc2397   \n",
       "4      5e006e98e3b6430a8b5b260426266922  62f51c24b3e4455fa36aa7466e884608   \n",
       "...                                 ...                               ...   \n",
       "68870  236472ed5205428f91f080ac2962229b  5fd8a3d606ed40ba864c479a6bdf80f0   \n",
       "68871  236472ed5205428f91f080ac2962229b  ca156c132a72490597e96a962e7ce7b4   \n",
       "68872  236472ed5205428f91f080ac2962229b  fbf542e01e49423485ee6ed332170084   \n",
       "68873  236472ed5205428f91f080ac2962229b  39579724cb2d447a8be28db79bca42e0   \n",
       "68874  236472ed5205428f91f080ac2962229b  122710774f3e49279c225a1f521eb17b   \n",
       "\n",
       "                           2  \n",
       "0      discourse#Declaration  \n",
       "1      discourse#Declaration  \n",
       "2      discourse#Declaration  \n",
       "3      discourse#Declaration  \n",
       "4      discourse#Declaration  \n",
       "...                      ...  \n",
       "68870  discourse#Declaration  \n",
       "68871  discourse#Declaration  \n",
       "68872  discourse#Declaration  \n",
       "68873  discourse#Declaration  \n",
       "68874  discourse#Declaration  \n",
       "\n",
       "[68875 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tuple(pull_last_values(p) for p in q) for q in qr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({rdflib.term.URIRef('http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#Declaration'): 68875})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([o for s,p,o in qr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg=ds.triples((None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#domain'),\n",
       " rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'),\n",
       " rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#Property'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace('http://www.semanticweb.org/tomk/ontologies/2022/11/discourse#')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disco_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
